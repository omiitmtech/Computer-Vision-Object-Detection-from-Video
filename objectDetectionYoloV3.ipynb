{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import neccessary python libraries\n",
    "import numpy as np      \n",
    "import cv2\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configuration files kept inside configFiles folder\n",
    "cocoFile = 'configFiles/coco.names'\n",
    "configFile = 'configFiles/yolov3.cfg'\n",
    "weightFile  = 'configFiles/yolov3.weights'\n",
    "\n",
    "#input video file to be passed from terminal\n",
    "# inputVideoFile = sys.argv[1]\n",
    "inputVideoFile = 'inputFiles/TopDown_AerialVideo_1080.mp4'\n",
    "\n",
    "#The object name that we want to detect will be passed from terminal\n",
    "# objectNameForDetection = sys.argv[2]\n",
    "objectNameForDetection = 'person'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import neccessary python libraries\n",
    "import numpy as np      \n",
    "import cv2\n",
    "import sys\n",
    "\n",
    "\n",
    "def detectHumansFromVideo(weightFile,configFile,inputVideoFile,objectName):\n",
    "# slow detection but very accurate accuracy\n",
    "    net = cv2.dnn.readNet(weightFile,configFile)\n",
    "\n",
    "    classes =[]\n",
    "    with open(cocoFile,'r') as f:\n",
    "        classes = f.read().splitlines()\n",
    "\n",
    "\n",
    "    cap = cv2.VideoCapture(inputVideoFile)\n",
    "\n",
    "    frame_width = int(cap.get(3))\n",
    "    frame_height = int(cap.get(4))\n",
    "    size = (frame_width, frame_height)\n",
    "    # Below VideoWriter object will create a frame of above defined sizeand the output is stored in output folder\n",
    "    # with a name ipudtfilename_processed.MJPG\n",
    "    outputFolder = '~/outputFiles'\n",
    "    #outfilename to save the processed video to the disk\n",
    "    outputFileName ='outputFiles/processedVideo.avi'\n",
    "    resultFile = cv2.VideoWriter(outputFileName, \n",
    "                         cv2.VideoWriter_fourcc(*'MJPG'),\n",
    "                         10, size)\n",
    "    while True :\n",
    "        ret,frame = cap.read()\n",
    "        if ret == True: \n",
    "            height, width,_ = frame.shape\n",
    "            blob = cv2.dnn.blobFromImage(frame,1/255,(640,640),(0,0,0),swapRB= True,crop=False)\n",
    "            net.setInput(blob)\n",
    "            output_layer_names = net.getUnconnectedOutLayersNames()\n",
    "            layerOutput = net.forward(output_layer_names)\n",
    "            boxes =[]\n",
    "            confidences=[]\n",
    "            class_ids=[]\n",
    "            for output in layerOutput:\n",
    "                for detection in output:\n",
    "                    scores = detection[5:]\n",
    "                    class_id = np.argmax(scores)\n",
    "                    confidence = scores[class_id]\n",
    "                    if confidence >0.5:\n",
    "                        center_x =int(detection[0]* width)\n",
    "                        center_y =int(detection[1]* height)\n",
    "                        w  =int(detection[2]* width)\n",
    "                        h  =int(detection[3]*height)\n",
    "                        x= int (center_x - w/2)\n",
    "                        y= int (center_y - h/2)\n",
    "                        #to draw a rectangle around a frame\n",
    "                        boxes.append([x,y,w,h])\n",
    "                        #to display the confidence score\n",
    "                        confidences.append((float(confidence)))\n",
    "                        #to append the class name\n",
    "                        class_ids.append(class_id)\n",
    "\n",
    "            indexes = cv2.dnn.NMSBoxes(boxes,confidences,0.5,0.4)\n",
    "            if len(indexes)!=0:\n",
    "                font = cv2.FONT_HERSHEY_PLAIN\n",
    "                # colors = np.random.uniform(0,255,size=(len(boxes),3))\n",
    "                for i in indexes.flatten():\n",
    "                    x,y,w,h = boxes[i]\n",
    "                    label = str(classes[class_ids[i]])\n",
    "                    confidence= str(round(confidences[i],2 ))\n",
    "                    color = [0, 0, 255]\n",
    "                    #it will not detect the objects other than the passed object name from the terminal\n",
    "                    # if label equals to passed object name then, it will draw a rectangle and print confidence score\n",
    "                    if label == objectName:\n",
    "                        cv2.rectangle(frame,(x,y),(x+w,y+h),color,2)\n",
    "                        cv2.putText(frame,label+\" \" + confidence,(x,y+20),font,2,(255,255,255),2)\n",
    "                    else:\n",
    "                        pass\n",
    "\n",
    "            resultFile.write(frame)\n",
    "            cv2.imshow('Frame',frame)\n",
    "            #press s on the keyboard to interrupt the process\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    resultFile.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call the function to perform object detection\n",
    "detectHumansFromVideo(weightFile,configFile,inputVideoFile,objectNameForDetection)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
